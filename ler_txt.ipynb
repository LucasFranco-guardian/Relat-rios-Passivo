{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5a1b9a0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "Python int too large to convert to C long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mcsv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfield_size_limit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxsize\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOverflowError\u001b[0m: Python int too large to convert to C long"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2238c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def ler_txt_escriturador(path_txt: str | Path, encoding: str = \"latin1\") -> pd.DataFrame:\n",
    "    path_txt = Path(path_txt)\n",
    "\n",
    "    # 1) Lê todas as linhas\n",
    "    with path_txt.open(\"r\", encoding=encoding, errors=\"replace\") as f:\n",
    "        linhas = [ln.rstrip(\"\\n\") for ln in f]\n",
    "\n",
    "    # 2) Acha a linha de cabeçalho \"real\"\n",
    "    idx_header = next(\n",
    "        (i for i, ln in enumerate(linhas) if ln.startswith(\"Data do Movimento;\")),\n",
    "        None\n",
    "    )\n",
    "    if idx_header is None:\n",
    "        raise ValueError(\"Não encontrei a linha de cabeçalho que começa com 'Data do Movimento;'\")\n",
    "\n",
    "    header_line = linhas[idx_header]\n",
    "\n",
    "    # 3) Seleciona apenas as linhas de dados (as que começam com data dd/mm/aaaa)\n",
    "    #    (ignora abertura e footer técnico)\n",
    "    data_lines = [\n",
    "        ln for ln in linhas[idx_header + 1:]\n",
    "        if len(ln) >= 10 and ln[2] == \"/\" and ln[5] == \"/\"  # padrão simples dd/mm/yyyy\n",
    "    ]\n",
    "\n",
    "    # 4) Monta um CSV em memória (cabeçalho + dados) e lê com pandas\n",
    "    from io import StringIO\n",
    "    csv_text = header_line + \"\\n\" + \"\\n\".join(data_lines)\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        StringIO(csv_text),\n",
    "        sep=\";\",\n",
    "        dtype=str,          # lê tudo como texto primeiro (evita bagunça com CPF, CEP etc.)\n",
    "        engine=\"python\"\n",
    "    )\n",
    "\n",
    "    # 5) Remove colunas vazias criadas por ';' no final das linhas\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "\n",
    "    # 6) (Opcional) Converter colunas numéricas com vírgula decimal\n",
    "    # Exemplo: \"Quantidade de Ativos\" vem como \"5549390,000\"\n",
    "    if \"Quantidade de Ativos\" in df.columns:\n",
    "        df[\"Quantidade de Ativos\"] = (\n",
    "            df[\"Quantidade de Ativos\"]\n",
    "            .str.replace(\".\", \"\", regex=False)     # se tiver separador de milhar\n",
    "            .str.replace(\",\", \".\", regex=False)    # vírgula -> ponto\n",
    "        )\n",
    "        df[\"Quantidade de Ativos\"] = pd.to_numeric(df[\"Quantidade de Ativos\"], errors=\"coerce\")\n",
    "\n",
    "    # 7) (Opcional) Converter datas principais\n",
    "    if \"Data do Movimento\" in df.columns:\n",
    "        df[\"Data do Movimento\"] = pd.to_datetime(df[\"Data do Movimento\"], dayfirst=True, errors=\"coerce\")\n",
    "    if \"Data de Nascimento / Fundação\" in df.columns:\n",
    "        df[\"Data de Nascimento / Fundação\"] = pd.to_datetime(df[\"Data de Nascimento / Fundação\"], errors=\"coerce\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "44f5d0f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "field larger than field limit (131072)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\LucasCavalcante\\Desktop\\Relatorio_Passivos_Guardian\\Relat-rios-Passivo\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:805\u001b[0m, in \u001b[0;36mPythonParser._next_iter_line\u001b[1;34m(self, row_num)\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 805\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;66;03m# for mypy\u001b[39;00m\n",
      "\u001b[1;31mError\u001b[0m: field larger than field limit (131072)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mler_txt_escriturador\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mteste11_parte_14.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn[1], line 32\u001b[0m, in \u001b[0;36mler_txt_escriturador\u001b[1;34m(path_txt, encoding)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringIO\n\u001b[0;32m     30\u001b[0m csv_text \u001b[38;5;241m=\u001b[39m header_line \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(data_lines)\n\u001b[1;32m---> 32\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mStringIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_text\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# lê tudo como texto primeiro (evita bagunça com CPF, CEP etc.)\u001b[39;49;00m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpython\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     37\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# 5) Remove colunas vazias criadas por ';' no final das linhas\u001b[39;00m\n\u001b[0;32m     40\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\LucasCavalcante\\Desktop\\Relatorio_Passivos_Guardian\\Relat-rios-Passivo\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LucasCavalcante\\Desktop\\Relatorio_Passivos_Guardian\\Relat-rios-Passivo\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LucasCavalcante\\Desktop\\Relatorio_Passivos_Guardian\\Relat-rios-Passivo\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\LucasCavalcante\\Desktop\\Relatorio_Passivos_Guardian\\Relat-rios-Passivo\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:252\u001b[0m, in \u001b[0;36mPythonParser.read\u001b[1;34m(self, rows)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mself\u001b[39m, rows: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    248\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\n\u001b[0;32m    249\u001b[0m     Index \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, Sequence[Hashable] \u001b[38;5;241m|\u001b[39m MultiIndex, Mapping[Hashable, ArrayLike]\n\u001b[0;32m    250\u001b[0m ]:\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 252\u001b[0m         content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_chunk:\n",
      "File \u001b[1;32mc:\\Users\\LucasCavalcante\\Desktop\\Relatorio_Passivos_Guardian\\Relat-rios-Passivo\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:1140\u001b[0m, in \u001b[0;36mPythonParser._get_lines\u001b[1;34m(self, rows)\u001b[0m\n\u001b[0;32m   1137\u001b[0m rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1140\u001b[0m     next_row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_iter_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1141\u001b[0m     rows \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m next_row \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\LucasCavalcante\\Desktop\\Relatorio_Passivos_Guardian\\Relat-rios-Passivo\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:834\u001b[0m, in \u001b[0;36mPythonParser._next_iter_line\u001b[1;34m(self, row_num)\u001b[0m\n\u001b[0;32m    825\u001b[0m         reason \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    826\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError could possibly be due to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    827\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparsing errors in the skipped footer rows \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    830\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall rows).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m         )\n\u001b[0;32m    832\u001b[0m         msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m reason\n\u001b[1;32m--> 834\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_alert_malformed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_num\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LucasCavalcante\\Desktop\\Relatorio_Passivos_Guardian\\Relat-rios-Passivo\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:781\u001b[0m, in \u001b[0;36mPythonParser._alert_malformed\u001b[1;34m(self, msg, row_num)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;124;03mAlert a user about a malformed row, depending on value of\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;124;03m`self.on_bad_lines` enum.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;124;03m    even though we 0-index internally.\u001b[39;00m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_bad_lines \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBadLineHandleMethod\u001b[38;5;241m.\u001b[39mERROR:\n\u001b[1;32m--> 781\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParserError(msg)\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_bad_lines \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBadLineHandleMethod\u001b[38;5;241m.\u001b[39mWARN:\n\u001b[0;32m    783\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    785\u001b[0m         ParserWarning,\n\u001b[0;32m    786\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    787\u001b[0m     )\n",
      "\u001b[1;31mParserError\u001b[0m: field larger than field limit (131072)"
     ]
    }
   ],
   "source": [
    "df = ler_txt_escriturador(\"teste11_parte_14.txt\")\n",
    "print(df.head())\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fb270250",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"saldo_teste11_parte13.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52d68979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contar_linhas(path_txt, encoding=\"latin1\"):\n",
    "    with open(path_txt, \"r\", encoding=encoding, errors=\"ignore\") as f:\n",
    "        return sum(1 for _ in f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e14cc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_txt_em_duas_partes(\n",
    "    path_txt,\n",
    "    output_1,\n",
    "    output_2,\n",
    "    encoding=\"latin1\"\n",
    "):\n",
    "    total_linhas = contar_linhas(path_txt, encoding)\n",
    "    metade = total_linhas // 2\n",
    "\n",
    "    with open(path_txt, \"r\", encoding=encoding, errors=\"ignore\") as fin, \\\n",
    "         open(output_1, \"w\", encoding=encoding) as f1, \\\n",
    "         open(output_2, \"w\", encoding=encoding) as f2:\n",
    "\n",
    "        for i, linha in enumerate(fin):\n",
    "            if i < metade:\n",
    "                f1.write(linha)\n",
    "            else:\n",
    "                f2.write(linha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "26f2499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dividir_txt_em_duas_partes(\n",
    "    \"teste11_parte_12.txt\",\n",
    "    \"teste11_parte_13.txt\",\n",
    "    \"teste11_parte_14.txt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84c5e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "def ler_txt_escriturador_grande_sem_aspas(path_txt, encoding=\"latin1\"):\n",
    "    path_txt = Path(path_txt)\n",
    "\n",
    "    # acha header\n",
    "    with path_txt.open(\"r\", encoding=encoding, errors=\"replace\") as f:\n",
    "        idx_header = None\n",
    "        for i, ln in enumerate(f):\n",
    "            if ln.startswith(\"Data do Movimento;\"):\n",
    "                idx_header = i\n",
    "                break\n",
    "    if idx_header is None:\n",
    "        raise ValueError(\"Não encontrei a linha de cabeçalho 'Data do Movimento;'\")\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        path_txt,\n",
    "        sep=\";\",\n",
    "        skiprows=idx_header,\n",
    "        header=0,\n",
    "        dtype=str,\n",
    "        encoding=encoding,\n",
    "        engine=\"c\",\n",
    "        quoting=csv.QUOTE_NONE,   # <- IGNORA aspas\n",
    "        on_bad_lines=\"skip\"\n",
    "    )\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84b123fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Data do Movimento Código do Escriturador CPF/CNPJ do Investidor  \\\n",
      "0        08/01/2026                    359            99716950900   \n",
      "1        08/01/2026                    359            99719053615   \n",
      "2        08/01/2026                    359            99724286134   \n",
      "3        08/01/2026                    359            99728788720   \n",
      "4        08/01/2026                    359            99730359504   \n",
      "\n",
      "  Data de Nascimento / Fundação Código de Dependência  \\\n",
      "0                    1974-11-27                     1   \n",
      "1                    1973-10-10                     1   \n",
      "2                    1984-02-06                     1   \n",
      "3                    1967-05-16                     1   \n",
      "4                    1980-12-07                     1   \n",
      "\n",
      "                                  Nome do Investidor Tipo de Pessoa  \\\n",
      "0  MARCELO RODRIGUES DE OLIVEIRA                 ...              F   \n",
      "1  PAULO ROBERTO SILVA                           ...              F   \n",
      "2  HELISANGELA NAVARRO DOS SANTOS                ...              F   \n",
      "3  ANDRE MIRANDA BURELLO                         ...              F   \n",
      "4  ISABEL CRISTINA NUNES BARCELOS                ...              F   \n",
      "\n",
      "  Tipo de Investidor Código de Atividade Sexo  ... Número do Documento  \\\n",
      "0                101                 145    M  ...            59576232   \n",
      "1                101                 214    M  ...             6692399   \n",
      "2                101                 108    F  ...             4259963   \n",
      "3                101                 109    M  ...          4129168355   \n",
      "4                101                 109    F  ...             1473066   \n",
      "\n",
      "  Tipo de Documento Sigla do País de Origem   Código ISIN  \\\n",
      "0                RG                     BRA  BRGARECTF001   \n",
      "1                RG                     BRA  BRGARECTF001   \n",
      "2                RG                     BRA  BRGARECTF001   \n",
      "3                RG                     BRA  BRGARECTF001   \n",
      "4                RG                     BRA  BRGARECTF001   \n",
      "\n",
      "  Nome da Sociedade Emissora Especificação Quantidade de Ativos  \\\n",
      "0               FII GUARDIAN  CI  ER                     12,000   \n",
      "1               FII GUARDIAN  CI  ER                    416,000   \n",
      "2               FII GUARDIAN  CI  ER                     16,000   \n",
      "3               FII GUARDIAN  CI  ER                   3250,000   \n",
      "4               FII GUARDIAN  CI  ER                    141,000   \n",
      "\n",
      "  Tipo de Gravame Indicador de Saldo Analítico Tipo de Ativo  \n",
      "0               1                            N           012  \n",
      "1               1                            N           012  \n",
      "2               1                            N           012  \n",
      "3               1                            N           012  \n",
      "4               1                            N           012  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "(442152, 32)\n"
     ]
    }
   ],
   "source": [
    "df = ler_txt_escriturador_grande_sem_aspas(\"teste11_ler_txt.txt\")\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9baa9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"saldo_teste11_.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
